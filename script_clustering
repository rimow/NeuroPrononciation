import numpy as np
from sklearn import cluster
from analyse import pourcentage , CoeffsHistogrammes , getY_v_non_v , histogrammesPhonemes
from mfcc import mfcc
from minibatch import initialisation_centres
from utiles import getY, getPhonemeDict

#extraction de features######################################################################################


fft_span = 0.02
hop_span = 0.01
n_mels = 40
fmin = 50
fmax = 8000
path = "/home/marianne/Developpement/Bref80_L4M01.wav"
#X = fbank(path,fft_span,hop_span,n_mels,fmin,fmax)
X = mfcc(path, fft_span, hop_span, n_mels)
X = np.transpose(X)
nb_features,nb_vectors = X.shape


#Initialisation du tableau contenant les donnees d'alignement################################################
beginning = []
end = []
phonemes = []
#lecture fichier alignement
alignement = open("/home/marianne/Developpement/Bref80_L4M01.aligned")
lines  = alignement.readlines()
alignement.close()
for line in lines:
    decomposed_line = line.split(' ')
    beginning.append(float(decomposed_line[0]))
    end.append(float(decomposed_line[1]))
    ph = decomposed_line[2].split('\n')
    phonemes.append(ph[0])

#Creation du vecteur Y contenant le phoneme correspondant pour chacun des vecteurs
phoneme_courant = 0;
Y = []
for i in range(nb_vectors):
    if (end[phoneme_courant]<hop_span*i and phoneme_courant<len(phonemes)-2): #on enleve le dernier qui ne compte pas
        phoneme_courant = phoneme_courant + 1
    #if not(phoneme_courant==len(phonemes)-2):
    Y.append(phonemes[phoneme_courant])   #On peut faire plus precis sans doute
Y = np.array(Y)


#clustering #################################################################################################"

print 'Clustering sur toutes les lettres : \n'
#kmeans
dict_path = "/home/marianne/Developpement/neuroPrononciation/classement"
dict = getPhonemeDict(dict_path)
nb_cluster = 3
sous = initialisation_centres(nb_cluster, X.transpose())

clus = cluster.KMeans(n_clusters=nb_cluster, init=sous, n_init=50, max_iter=3000, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=1)
f = open("pourcentages3.csv", "a")
f.write("KMEANS\n")
f.close()

y = clus.fit_predict(X.transpose())
X2 = getY(X.transpose(),"/home/marianne/Developpement/Bref80_L4M01.aligned", 0.01)

#si l'algorithme est non supervise mettre nmax au lieu de nb_cluster
# pourcentage(X2 , nb_cluster, y , dict_path , 0)
# pourcentage(X2 , nb_cluster, y , dict_path , 1)
# pourcentage(X2 , nb_cluster, y , dict_path , 2)
histogrammesPhonemes(nb_cluster, y , X2)

# clus = cluster.AgglomerativeClustering(nb_cluster)
# f = open("pourcentages2.csv", "a")
# f.write("AgglomerativeClustering\n")
# f.close()
#
# y = clus.fit_predict(X.transpose())
# X2 = getY(X.transpose(),"/home/marianne/Developpement/Bref80_L4M01.aligned", 0.01)
#
# #si l'algorithme est non supervise mettre nmax au lieu de nb_cluster
# pourcentage(X2 , nb_cluster, y , dict_path , 0)
# pourcentage(X2 , nb_cluster, y , dict_path , 1)
# pourcentage(X2 , nb_cluster, y , dict_path , 2)
# # histogrammesPhonemes(nb_cluster, y , X2)
#
#
#
# # Algorithmes ou on ne fixe pas le nombre de clusters
# clus = cluster.MeanShift(bandwidth=None, seeds=None, bin_seeding=False, min_bin_freq=1, cluster_all=True, n_jobs=1)
# f = open("pourcentages2.csv", "a")
# f.write("MeanShift\n")
# f.close()
#
# y = clus.fit_predict(X.transpose())
# nmax = max(y)+1
# X2 = getY(X.transpose(),"/home/marianne/Developpement/Bref80_L4M01.aligned", 0.01)
#
# #si l'algorithme est non supervise mettre nmax au lieu de nb_cluster
# pourcentage(X2 , nmax, y , dict_path , 0)
# pourcentage(X2 , nmax, y , dict_path , 1)
# pourcentage(X2 , nmax, y , dict_path , 2)
# # histogrammesPhonemes(nb_cluster, y , X2)


#marche pas
#clus = cluster.DBSCAN(eps=0.5, min_samples=5, metric='euclidean', algorithm='auto', leaf_size=30, p=None, random_state=None)
#clus = cluster.spectral_clustering(affinity, n_clusters=8, n_components=None, eigen_solver=None, random_state=None, n_init=10, eigen_tol=0.0, assign_labels='kmeans')
#clus = cluster.SpectralClustering(n_clusters=3, eigen_solver=None, random_state=None, n_init=10, gamma=1.0, affinity='rbf', n_neighbors=10, eigen_tol=0.0, assign_labels='kmeans', degree=3, coef0=1, kernel_params=None)
#clus = cluster.ward_tree(X, connectivity=None, n_components=None, n_clusters=None, return_distance=False)


# y = clus.fit_predict(X.transpose())
# nmax = max(y)
# X2 = getY(X.transpose(),"/home/marianne/Developpement/Bref80_L4M01.aligned", 0.01)
#
# #si l'algorithme est non supervise mettre nmax au lieu de nb_cluster
# pourcentage(X2 , nb_cluster, y , dict_path , 0)
# pourcentage(X2 , nb_cluster, y , dict_path , 1)
# pourcentage(X2 , nb_cluster, y , dict_path , 2)
#
# X_shape = X2.shape
# yv = getY_v_non_v(X2 , dict , 1)
# #CoeffsHistogrammes(X2 , 5 , yv , 0 , X_shape[1]-2)
# histo
